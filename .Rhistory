model_gausspoly$results$RMSE[[6]]^2
# print(model_gausspoly)
# fit bayesian glm
set.seed(123)
model_bayesglm <- train(CPI~GDP+Export, data = train_data, method="bayesglm", trControl=train_control, na.action = na.omit)
model_bayesglm$results$MAE
model_bayesglm$results$RMSE^2
# print(model_bayesglm)
train_data %>% plot(CPI,GDP)
plot(train_data$GDP,train_data$CPI)
plot(train_data$Export,train_data$CPI)
plot(train_data$GDP,train_data$CPI)
remove(list = ls())
options(warn=-1)
set.seed(1337)
library(here)
library(tidyverse)
library(lubridate)
library(caret)
library(GGally)
library(tm) # Remove numbers
library('ggplot2') # visualization
library('ggthemes') # visualization
library('mice') # imputation
library('randomForest') # classification algorithm
library("e1071")
# Functions #####
cabinToDeck <- function(cabin){
deck <- gsub('[[:digit:]]', '', cabin)
deck <- substring(deck,1,1) %>% as_factor()
return(deck)
}
countNA <- function(x){sum(is.na(x))}
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- bind_rows(train_set,test_set) %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
View(original_data)
View(train_set)
descriptives
remove(list = ls())
options(warn=-1)
set.seed(1337)
library(here)
library(tidyverse)
library(lubridate)
library(caret)
library(GGally)
library(tm) # Remove numbers
library('ggplot2') # visualization
library('ggthemes') # visualization
library('mice') # imputation
library('randomForest') # classification algorithm
library("e1071")
# Functions #####
cabinToDeck <- function(cabin){
deck <- gsub('[[:digit:]]', '', cabin)
deck <- substring(deck,1,1) %>% as_factor()
return(deck)
}
countNA <- function(x){sum(is.na(x))}
# Rest #####
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- bind_rows(train_set,test_set) %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data)
descriptives
remove(list = ls())
options(warn=-1)
set.seed(1337)
library(here)
library(tidyverse)
library(lubridate)
library(caret)
library(GGally)
library(tm) # Remove numbers
library('ggplot2') # visualization
library('ggthemes') # visualization
library('mice') # imputation
library('randomForest') # classification algorithm
library("e1071")
# Functions #####
cabinToDeck <- function(cabin){
deck <- gsub('[[:digit:]]', '', cabin)
deck <- substring(deck,1,1) %>% as_factor()
return(deck)
}
countNA <- function(x){sum(is.na(x))}
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- bind_rows(train_set,test_set) %>% as_tibble()
View(original_data)
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data)
descriptives
missingvalues <- map(cleaned_data, countNA) %>% as_tibble()
missingvalues
temp_data <- mice(cleaned_data %>% select(-PassengerId),
m = 1, meth = 'pmm', maxit = 50, print=FALSE, seed = 1337)
imputed_data <- complete(temp_data, 1) %>%
as_tibble() %>%
mutate(PassengerId = cleaned_data$PassengerId) %>%
select(8,1:7) %>%
select(-Fare)
(desc_table <- summary(imputed_data))
(desc_plot <- ggpairs(imputed_data %>% select(-c(PassengerId))))
# Two classifiers with cross validation
train_set <- imputed_data[1:train_size,]
test_set <- imputed_data[train_size:nrow(imputed_data),]
View(test_set)
original_data <- train_set %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- train_set %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data)
descriptives
missingvalues <- map(cleaned_data, countNA) %>% as_tibble()
missingvalues
temp_data <- mice(cleaned_data %>% select(-PassengerId),
m = 1, meth = 'pmm', maxit = 50, print=FALSE, seed = 1337)
imputed_data <- complete(temp_data, 1) %>%
as_tibble() %>%
mutate(PassengerId = cleaned_data$PassengerId) %>%
select(8,1:7) %>%
select(-Fare)
(desc_table <- summary(imputed_data))
# Two classifiers with cross validation
train_set <- imputed_data[1:train_size,]
remove(list = ls())
options(warn=-1)
set.seed(1337)
library(here)
library(tidyverse)
library(lubridate)
library(caret)
library(GGally)
library(tm) # Remove numbers
library('ggplot2') # visualization
library('ggthemes') # visualization
library('mice') # imputation
library('randomForest') # classification algorithm
library("e1071")
# Functions #####
cabinToDeck <- function(cabin){
deck <- gsub('[[:digit:]]', '', cabin)
deck <- substring(deck,1,1) %>% as_factor()
return(deck)
}
countNA <- function(x){sum(is.na(x))}
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- bind_rows(train_set,test_set) %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data)
descriptives
missingvalues <- map(cleaned_data, countNA) %>% as_tibble()
missingvalues
View(cleaned_data)
temp_data <- mice(cleaned_data %>% select(-PassengerId),
m = 1, meth = 'pmm', maxit = 50, print=FALSE, seed = 1337)
missingvalues <- map(cleaned_data, countNA) %>% as_tibble()
missingvalues
missingvalues <- map(temp_data, countNA) %>% as_tibble()
missingvalues
remove(list = ls())
options(warn=-1)
set.seed(1337)
library(here)
library(tidyverse)
library(lubridate)
library(caret)
library(GGally)
library(tm) # Remove numbers
library('ggplot2') # visualization
library('ggthemes') # visualization
library('mice') # imputation
library('randomForest') # classification algorithm
library("e1071")
# Functions #####
cabinToDeck <- function(cabin){
deck <- gsub('[[:digit:]]', '', cabin)
deck <- substring(deck,1,1) %>% as_factor()
return(deck)
}
countNA <- function(x){sum(is.na(x))}
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- bind_rows(train_set,test_set) %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data)
descriptives
missingvalues <- map(cleaned_data, countNA) %>% as_tibble()
missingvalues
temp_data <- mice(cleaned_data %>% select(-PassengerId),
m = 1, meth = 'pmm', maxit = 50, print=FALSE, seed = 1337)
imputed_data <- complete(temp_data, 1) %>%
as_tibble() %>%
mutate(PassengerId = cleaned_data$PassengerId) %>%
select(8,1:7) %>%
select(-Fare)
missingvalues <- map(imputed_data, countNA) %>% as_tibble()
missingvalues
View(imputed_data)
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data)
descriptives
missingvalues <- map(cleaned_data, countNA) %>% as_tibble()
missingvalues
temp_data <- mice(cleaned_data %>% select(-PassengerId,-Survived),
m = 1, meth = 'pmm', maxit = 50, print=FALSE, seed = 1337)
imputed_data <- complete(temp_data, 1) %>%
as_tibble() %>%
mutate(PassengerId = cleaned_data$PassengerId) %>%
select(8,1:7) %>%
select(-Fare)
imputed_data <- complete(temp_data, 1) %>%
as_tibble() %>%
mutate(PassengerId = cleaned_data$PassengerId) %>%
select(7,1:6) %>%
select(-Fare)
missingvalues <- map(imputed_data, countNA) %>% as_tibble()
missingvalues
temp_data <- mice(cleaned_data %>% select(-PassengerId,-Survived),
m = 1, meth = 'pmm', maxit = 50, print=FALSE, seed = 1337)
imputed_data <- complete(temp_data, 1) %>%
as_tibble() %>%
mutate(PassengerId = cleaned_data$PassengerId, Survived = cleaned_data$Survived) %>%
select(8,1:7) %>%
select(-Fare)
missingvalues <- map(imputed_data, countNA) %>% as_tibble()
missingvalues
# Two classifiers with cross validation
train_set <- imputed_data[1:train_size,]
test_set <- imputed_data[train_size:nrow(imputed_data),]
View(train_set)
View(test_set)
test_set <- imputed_data[train_size+1:nrow(imputed_data),]
remove(list = ls())
options(warn=-1)
set.seed(1337)
library(here)
library(tidyverse)
library(lubridate)
library(caret)
library(GGally)
library(tm) # Remove numbers
library('ggplot2') # visualization
library('ggthemes') # visualization
library('mice') # imputation
library('randomForest') # classification algorithm
library("e1071")
# Functions #####
cabinToDeck <- function(cabin){
deck <- gsub('[[:digit:]]', '', cabin)
deck <- substring(deck,1,1) %>% as_factor()
return(deck)
}
countNA <- function(x){sum(is.na(x))}
# Rest #####
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- bind_rows(train_set,test_set) %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data)
descriptives
missingvalues <- map(cleaned_data, countNA) %>% as_tibble()
missingvalues
temp_data <- mice(cleaned_data %>% select(-PassengerId,-Survived),
m = 1, meth = 'pmm', maxit = 50, print=FALSE, seed = 1337)
imputed_data <- complete(temp_data, 1) %>%
as_tibble() %>%
mutate(PassengerId = cleaned_data$PassengerId, Survived = cleaned_data$Survived) %>%
select(8,1:7) %>%
select(-Fare)
missingvalues <- map(imputed_data, countNA) %>% as_tibble()
missingvalues
(desc_table <- summary(imputed_data))
# (desc_plot <- ggpairs(imputed_data %>% select(-c(PassengerId))))
# Two classifiers with cross validation
train_set <- imputed_data[1:train_size,]
test_set <- imputed_data[train_size+1:nrow(imputed_data),]
test_set <- imputed_data[(train_size+1):nrow(imputed_data),]
train_control <- trainControl(method="cv", number=10)
model_rf <- train(Survived ~ Pclass + Sex + Age + FamSize + Deck,
data = train_set,  method="rf", metric = "Accuracy",
trControl=train_control,na.action = na.omit)
model_svm <- train(Survived ~ Pclass + Sex + Age + FamSize + Deck,
data = train_set,  method="svmRadial",metric = "Accuracy",
trControl=train_control, na.action = na.omit)
results <- resamples(list(rf = model_rf, svm = model_svm))
summary(results)
dotplot(results)
predictions <- predict(model_rf, test_set)
confusionMatrix(predictions, test_set$Survived)
predictions
confusionMatrix(predictions, train_set$Survived)
View(test_set)
# Save the solution to a dataframe with two columns: PassengerId and Survived (prediction)
solution <- data.frame(PassengerID = test_set$PassengerId, Survived = prediction)
# Save the solution to a dataframe with two columns: PassengerId and Survived (prediction)
solution <- data.frame(PassengerID = test_set$PassengerId, Survived = predictions)
# Write the solution to file
write.csv(solution, file = '/data/titanic/rf_mod_Solution.csv', row.names = F)
# Write the solution to file
write.csv(solution, file = './data/titanic/rf_mod_Solution.csv', row.names = F)
library(tidyverse)
library(quanteda)
sms <- read_delim("data/sms/SmsCollection.csv",
";", escape_double = FALSE, trim_ws = TRUE) %>% as_tibble()
table(sms$label)
remove(list = ls())
sms <- read_delim("data/sms/SmsCollection.csv",
";", escape_double = FALSE, trim_ws = TRUE) %>% as_tibble()
table(sms$label)
names(sms)
sms %>% head()
msg.corpus<-corpus(sms$text)
#separating Train and test data
sms_train<-sms[1:4458,]
sms_test<-sms[(4458+1):nrow(sms),]
msg.dfm <- dfm(msg.corpus, tolower = TRUE)  #generating document freq matrix
msg.dfm <- dfm_trim(msg.dfm, min_count = 5, min_docfreq = 3)
msg.dfm <- dfm_weight(msg.dfm)
#trining and testing data of dfm
msg.dfm.train<-msg.dfm[1:4458,]
msg.dfm.test<-msg.dfm[4458:nrow(sms),]
nb.classifier<-textmodel_nb(msg.dfm.train,sms.train[,1])
library(quanteda)
nb.classifier<-textmodel_nb(msg.dfm.train,sms.train[,1])
nb.classifier<-quanteda::textmodel_nb(msg.dfm.train,sms.train[,1])
install.packages(quanteda)
install.packages('quanteda')
install.packages("quanteda")
library(quanteda)
nb.classifier<-quanteda::textmodel_nb(msg.dfm.train,sms.train[,1])
nb.classifier<-textmodel_nb(msg.dfm.train,sms.train[,1])
nb.classifier<-textmodel_NB(msg.dfm.train,sms.train[,1])
library(quanteda.textmodels)
table(sms$label)
names(sms)
sms %>% head()
descriptives <- summary(cleaned_data[1:train_size,])
remove(list = ls())
options(warn=-1)
set.seed(1337)
library(here)
library(tidyverse)
library(lubridate)
library(caret)
library(GGally)
library(tm) # Remove numbers
library('ggplot2') # visualization
library('ggthemes') # visualization
library('mice') # imputation
library('randomForest') # classification algorithm
library("e1071")
# Functions #####
cabinToDeck <- function(cabin){
deck <- gsub('[[:digit:]]', '', cabin)
deck <- substring(deck,1,1) %>% as_factor()
return(deck)
}
countNA <- function(x){sum(is.na(x))}
# Rest #####
train_set <- read_csv('./data/titanic/train.csv')
test_set  <- read_csv('./data/titanic/test.csv')
train_size <- nrow(train_set) %>% as.numeric()
original_data <- bind_rows(train_set,test_set) %>% as_tibble()
cleaned_data <- original_data %>%
select(-c(Name, Ticket, Embarked)) %>%
mutate(PassengerId = as.factor(PassengerId),
Sex = as_factor(Sex),
Survived = as.factor(Survived),
FamSize = SibSp + Parch,
Deck = cabinToDeck(Cabin)) %>%
select(-c(SibSp, Parch, Cabin))
descriptives <- summary(cleaned_data[1:train_size,])
descriptives
View(train_set)
library(tidyverse)
library(quanteda)
library(quanteda.textmodels)
remove(list = ls())
sms <- read_delim("data/sms/SmsCollection.csv",
";", escape_double = FALSE, trim_ws = TRUE) %>% as_tibble()
table(sms$label)
names(sms)
sms %>% head()
msg.corpus<-corpus(sms$text)
#separating Train and test data
sms_train<-sms[1:4458,]
sms_test<-sms[(4458+1):nrow(sms),]
msg.dfm <- dfm(msg.corpus, tolower = TRUE)  #generating document freq matrix
msg.dfm <- dfm_trim(msg.dfm, min_count = 5, min_docfreq = 3)
msg.dfm <- dfm_weight(msg.dfm)
#trining and testing data of dfm
msg.dfm.train<-msg.dfm[1:4458,]
msg.dfm.test<-msg.dfm[4458:nrow(sms),]
nb.classifier<-textmodel_nb(msg.dfm.train,sms.train[,1])
nb.classifier<-textmodel_nb(msg.dfm.train,sms_train[,1])
nb.classifier<-textmodel_nb(msg.dfm.train,sms_train[,1], na.rm = T)
View(sms_train)
nb.classifier<-textmodel_nb(msg.dfm.train,sms_train$label)
nb.classifier
pred<-predict(nb.classifier,msg.dfm.test)
View(sms_test)
table(predicted=pred$nb.predicted,actual=sms_test$label)
table(predicted=pred,actual=sms_test$label)
length(pred)
library(tidyverse)
library(quanteda)
library(quanteda.textmodels)
# Dont use naieve bayes
# Follow quanteda tutorial
remove(list = ls())
sms <- read_delim("data/sms/SmsCollection.csv",
";", escape_double = FALSE, trim_ws = TRUE) %>% as_tibble()
table(sms$label)
names(sms)
sms %>% head()
msg.corpus<-corpus(sms$text)
#separating Train and test data
sms_train<-sms[1:4458,]
sms_test<-sms[(4458+1):nrow(sms),]
msg.dfm <- dfm(msg.corpus, tolower = TRUE)  #generating document freq matrix
msg.dfm <- dfm_trim(msg.dfm, min_count = 5, min_docfreq = 3)
msg.dfm <- dfm_weight(msg.dfm)
#trining and testing data of dfm
msg.dfm.train<-msg.dfm[1:4458,]
msg.dfm.test<-msg.dfm[(4458+1):nrow(sms),]
nb.classifier<-textmodel_nb(msg.dfm.train,sms_train$label)
nb.classifier
pred<-predict(nb.classifier,msg.dfm.test)
table(predicted=pred,actual=sms_test$label)
mean(pred$nb.predicted==sms_test[,1])*100
mean(pred==sms_test$label)*100
(4+17)/(917+138)
(1-(4+17)/(917+138))*100
confusionMatrix(pred,sms_test$label)
